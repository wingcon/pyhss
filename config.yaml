## HSS Parameters
hss:  
  # Transport Type. "TCP" and "SCTP" are valid options.
  # Note: SCTP works but is still experimental. TCP has been load-tested and performs in a production environment.
  transport: "TCP"
  #IP Addresses to bind on (List) - For TCP only the first IP is used, for SCTP all used for Transport (Multihomed).
  bind_ip: ["0.0.0.0"]

  #Port to listen on (Same for TCP & SCTP)
  bind_port: 3868

  #Value to populate as the OriginHost in Diameter responses
  OriginHost: "hss01"

  #Value to populate as the OriginRealm in Diameter responses
  OriginRealm: "epc.mnc001.mcc001.3gppnetwork.org"

  #Value to populate as the Product name in Diameter responses
  ProductName: "pyHSS"

  #Name of the Site, shown in API
  site_name: "Sydney"

  #Your Home Mobile Country Code (Used for PLMN calcluation)
  MCC: "001"
  #Your Home Mobile Network Code (Used for PLMN calcluation)
  MNC: "01"

  #Enable GMLC / SLh Interface
  SLh_enabled: False

  #IMSI of Test Subscriber for Unit Checks (Optional)
  test_sub_imsi: '001021234567890'

  #The maximum time to wait, in seconds, before disconnecting a client when no data is received.
  client_socket_timeout: 120

  #The maximum time to wait, in seconds, before disconnecting a client when no data is received.
  client_socket_timeout: 300

  #The maximum time to wait, in seconds, before discarding a diameter request.
  diameter_request_timeout: 3

  # Whether to send a DWR to connected peers.
  send_dwr: False

  # How often to send a DWR to connected peers if enabled, in seconds.
  send_dwr_interval: 5

  #The amount of time, in seconds, before purging a disconnected client from the Active Diameter Peers key in redis.
  active_diameter_peers_timeout: 10

  #Prevent updates from being performed without a valid 'Provisioning-Key' in the header
  lock_provisioning: False

  #Provisioning Key for this HSS, alias for an API key. Required to be present in the header of requests to this HSS' api, if lock_provisioning is True.
  provisioning_key: "changeThisKeyInProduction"

  #If enabled sends CLRs to old MME when new MME attaches active sub
  CancelLocationRequest_Enabled: False

  #Workaround for some MMEs to force an Insert Subscriber Data request to be sent immediately after ULA
  Insert_Subscriber_Data_Force: False

  #Default Initial Filter Criteria for IMS Subscribers
  #Jinja Formatted Template, see the example for variables passed to it.
  Default_iFC: 'default_ifc.xml'

  #Default Sh User Data
  Default_Sh_UserData: 'default_sh_user_data.xml'

  # Use either IMSI or MSISDN as user to search in database
  use_msisdn_as_user: False
  
  #S-CSCF Pool
  scscf_pool:
    - 'scscf.ims.mnc001.mcc001.3gppnetwork.org'

  roaming:
    outbound:
      # Whether or not to a subscriber to connect to an undefined network when outbound roaming.
      allow_undefined_networks: True

  # SCTP Socket Parameters
  sctp:
    rtoMax: 5000
    rtoMin: 500
    rtoInitial: 1000

  gsup:
    bind_ip: "0.0.0.0"
    bind_port: 4222

api:
  page_size: 200
  # Whether or not to return key-based data when querying the AUC. Disable in production systems.
  enable_insecure_auc: False

benchmarking:
  # Whether to enable benchmark logging
  enabled: True
  # How often to report, in seconds. Not all benchmarking supports interval reporting.
  reporting_interval: 3600

eir:
  imsi_imei_logging: True    #Store current IMEI / IMSI pair in backend
  no_match_response: 2       #Greylist
  store_offnet_imsi: False  # Whether or not to store an IMEI / IMSI pair that doesn't exist in the AUC
  simSwapNotification: False # If the IMEI for a stored IMSI/IMEI combo changes, notify the webhook endpoint
  # Define an optional TAC csv file path
  #tac_database_csv: '/etc/pyhss/tac_database.csv'

logging:
  level: INFO
  logfiles:
    hss_logging_file: /var/log/pyhss_hss.log
    diameter_logging_file: /var/log/pyhss_diameter.log
    geored_logging_file: /var/log/pyhss_geored.log
    metric_logging_file: /var/log/pyhss_metrics.log
  sqlalchemy_sql_echo: False
  sqlalchemy_pool_recycle: 15
  sqlalchemy_pool_size: 30
  sqlalchemy_max_overflow: 0

## Database Parameters
database:
  db_type: mysql    #Supported types are MySQL, Postgres and sqlite
  server: 127.0.0.1
  username: dbeaver
  password: password
  database: hss2 # for sqlite, this should be a path to the database file
  readCacheEnabled: True
  readCacheInterval: 60

## External Webhook Notifications
webhooks:
  enabled: False
  endpoints:
    - 'http://127.0.0.1:8181'

### Notifications to OCS on Credit Control Requests
ocs:
  enabled: False
  endpoints:
    - 'http://127.0.0.1:8282'

## Geographic Redundancy Parameters
geored:
  enabled: False
  sync_actions: ['HSS', 'IMS', 'PCRF', 'EIR']    #What event actions should be synced
  endpoints:                         #List of PyHSS API Endpoints to update
    - 'http://hss01.mnc001.mcc001.3gppnetwork.org:8080'
    - 'http://hss02.mnc001.mcc001.3gppnetwork.org:8080'

#Redis is required to run PyHSS. An instance running on a local network is recommended for production.
redis:
  # Which connection type to attempt. Valid options are: tcp, unix, sentinel
  # tcp - Connection via a standard TCP socket to a given host and port.
  # unix - Connect to redis via a unix socket, provided by unixSocketPath.
  # sentinel - Connect to one or more redis sentinel hosts.
  connectionType: "tcp"
  unixSocketPath: '/var/run/redis/redis-server.sock'
  host: localhost
  port: 6379
  sentinel:
    masterName: exampleMaster
    hosts:
      - exampleSentinel.mnc001.mcc001.3gppnetwork.org:
        port: 6379
        password: ''


prometheus:
  enabled: False
  port: 8081    #If the API is run the API runs on the next port number up from this
  async_subscriber_count: False    #If enabled the subscriber count will be updated asynchronously for Prometheus

influxdb:
  enabled: False
  host: "127.0.0.1"
  port: 8086
  username: exampleUser
  password: examplePassword
  database: example

snmp:
  port: 1161
  listen_address: 127.0.0.1
